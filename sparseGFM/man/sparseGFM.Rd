% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sparseGFM.R
\name{sparseGFM}
\alias{sparseGFM}
\title{Sparse Generalized Factor Model}
\usage{
sparseGFM(
  x,
  type = c("continuous", "count", "binary"),
  q = 2,
  penalty = c("lasso", "SCAD", "MCP", "group", "agroup", "gSCAD", "agSCAD", "gMCP",
    "agMCP", "alasso", "glasso", "aglasso"),
  lambda = 1,
  gam = 1,
  tau = NULL,
  mat_sd = 1,
  delta = 1e-04,
  maxiter = 30,
  C = 5,
  verbose = TRUE
)
}
\arguments{
\item{x}{A numeric matrix of observations (n x p), where n is the number of observations
and p is the number of variables}

\item{type}{Character string specifying the data type. Options are:
\itemize{
  \item "continuous": Gaussian family for continuous data
  \item "count": Poisson family for count data
  \item "binary": Binomial family for binary data
}}

\item{q}{Integer specifying the number of latent factors (default = 2)}

\item{penalty}{Character string specifying the penalty type for sparsity. Options include:
\itemize{
  \item "lasso": L1 penalty
  \item "alasso": Adaptive lasso penalty
  \item "SCAD": Smoothly clipped absolute deviation penalty
  \item "MCP": Minimax concave penalty
  \item "group"/"glasso": Group lasso penalty
  \item "agroup"/"aglasso": Adaptive group lasso penalty
  \item "gSCAD": Group SCAD penalty
  \item "agSCAD": Adaptive group SCAD penalty
  \item "gMCP": Group MCP penalty
  \item "agMCP": Adaptive group MCP penalty
}}

\item{lambda}{Numeric value for the penalty tuning parameter (default = 1)}

\item{gam}{Numeric value for the adaptive weight parameter in adaptive penalties (default = 1)}

\item{tau}{Numeric value for the shape parameter in SCAD/MCP penalties.
Default is 3.7 for SCAD and 3 for MCP if not specified}

\item{mat_sd}{Standard deviation for continuous data (default = 1)}

\item{delta}{Convergence tolerance for the iterative algorithm (default = 1e-4)}

\item{maxiter}{Maximum number of iterations (default = 30)}

\item{C}{Numeric value for the constraint bound to ensure stability (default = 5)}

\item{verbose}{Logical indicating whether to print iteration progress (default = TRUE)}
}
\value{
A list containing:
\itemize{
  \item FF_hat: Estimated factor matrix (n x q)
  \item BB_hat: Estimated loading matrix (p x q)
  \item alpha_hat: Estimated intercept vector (p x 1)
  \item obj_loglik: Log-likelihood value
  \item obj_pen: Penalized objective function value
  \item index: Indices of variables with zero loadings (selected out)
  \item df_est: Estimated degrees of freedom
  \item iter: Number of iterations performed
}
}
\description{
Implements sparse generalized factor models with various penalty functions for dimension reduction
and variable selection in high-dimensional data with different data types (continuous, count, binary).
}
\details{
The function implements an alternating minimization algorithm that iteratively updates
the factor matrix F and loading matrix B until convergence. Missing values are imputed
using column means (rounded for count/binary data). The algorithm includes identifiability
constraints and various penalty functions for inducing sparsity in the loading matrix.
}
\examples{
\dontrun{
# Generate example data
n <- 100; p <- 50
x <- matrix(rnorm(n*p), n, p)

# Fit sparse GFM with lasso penalty
result <- sparseGFM(x, type = "continuous", q = 2, penalty = "lasso", lambda = 0.5)
}

}
